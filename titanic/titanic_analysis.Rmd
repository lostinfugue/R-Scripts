---
title: "Titanic Analysis Learnings Summary"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Review material from Data Analysis and highlight key learnings


## (1) Initial Data Analysis
### Load data into R 
using `read.csv` method
```{r results = "hide"}
test <- read.csv("test.csv",header = TRUE)
train <- read.csv("train.csv",header = TRUE)
```

### Understand data

#### Look at Data Dictionary  
https://www.kaggle.com/c/titanic/data

Variable    | Definition           	 | Key                |
------------|------------------------|--------------------|
survival    | Survival               | 0 = No, 1 = Yes    |
pclass      |	Ticket class            |	1 = 1st, 2 = 2nd, 3 = 3rd |
sex         |	Sex	                    |                         |
age	| Age in years	| |
sibsp	| # of siblings / spouses aboard the Titanic	| |
parch	| # of parents / children aboard the Titanic	| |
ticket  |	Ticket number	  |
fare  |	Passenger fare	 |
cabin	| Cabin number	 |
embarked  |	Port of Embarkation	| C = Cherbourg, Q = Queenstown, S = Southampton  |
##### Variable Notes
**pclass**: A proxy for socio-economic status (SES)
1st = Upper
2nd = Middle
3rd = Lower

**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5

**sibsp**: The dataset defines family relations in this way...
Sibling = brother, sister, stepbrother, stepsister
Spouse = husband, wife (mistresses and fiancÃ©s were ignored)

**parch**: The dataset defines family relations in this way...
Parent = mother, father
Child = daughter, son, stepdaughter, stepson
Some children travelled only with a nanny, therefore parch=0 for them.

##### Notes:
* `survival` is the classification variable


#### Look at data itself
```{r}
head(train)
```
##### Notes:
* why don't the column names match the data dictionary.  fix that.
```{r results = "hide"}
colnames(train) <- tolower(colnames(train))
colnames(test) <- tolower(colnames(test))
```


#### Look at data structure
```{r}
str(train)
```
We can see the data types.


#### Look at summary statistics.  Understand prevelance of missing / null data.

```{r}
summary(train)
```

#### Look at train vs. test splits. 
* About 2/3 train (1:891), 1/3 test (892:1309) 
* Union together using `rbind()` into a combined dataframe in which we store any newly engineered features so that they are available both when training and testing our models.   
* At this point we can convert data types if it makes analysis easier.  or make a new column with the data with new data type.
```{r results="hide"}
## combine test and train datasets
test.survived <- data.frame(survived = rep("None",nrow(test)),test[,])
combined <- rbind(train, test.survived)

## change datatypes
combined$pclass <- as.factor(combined$pclass)
combined$survived <- as.factor(combined$survived)
combined$name <- as.character(combined$name)
```


### explore relationships between data fields vs. classification field `survived`

**Goal**: make hypotheses for which features have predictive power and why

#### Load Tools:
* `gmodels`: use `CrossTable` to easily make tables of counts & proportions
* `dplyr`: for aggregating data like sql/pivot table for proportions
* `ggplot2`: use for plots
* `cowplot`: use for plotting multiple graphs side-by-side
* `stringr`: use for manipulating strings
```{r message=FALSE} 
library(dplyr)
library(gmodels)
library(ggplot2)
library(cowplot)
library(stringr)
```


#### survived

* training set: 
    + 549 (62%) perished
    + 342 (38%) survived
```{r results="hide"}
## using gmodels CrossTable()
CrossTable(train$survived)
```
```{r}
## using dplyr
combined[1:891,] %>% 
  group_by(survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))
```

#### pclass
Predictive? **Yes**

* survival rates 
    + 63% in 1st class
    + 48% in 2nd class
    + 24% in 3rd class
```{r echo=FALSE, eval=FALSE}
combined[1:891,] %>% 
  group_by(pclass, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))
```
* % of passengers 
    + 3rd class: 55%
    + 1st: 24%
    + 2nd: 21%
```{r echo=FALSE, eval=FALSE}
combined[1:891,] %>% 
  group_by(pclass) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count), pct2 = count/sum(sum(count)))
```

```{r echo=FALSE}
pclass.summary <- combined[1:891,] %>% 
  group_by(pclass, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

a1 <- ggplot(pclass.summary, aes(x= pclass, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

a2 <- ggplot(pclass.summary, aes(x= pclass, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

cowplot::plot_grid(a1,a2, ncol=1, labels = "AUTO")
```

#### sex
Predictive: **Yes**

* survival rates 
    + 74% for female
    + 19% for male
```{r echo=FALSE, eval=FALSE}
combined[1:891,] %>% 
  group_by(sex, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))
```

```{r echo=FALSE}
sex.summary <- combined[1:891,] %>% 
  group_by(sex, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

b1 <- ggplot(sex.summary, aes(x= sex, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

b2 <- ggplot(sex.summary, aes(x= sex, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

cowplot::plot_grid(b1,b2, ncol=1, labels = "AUTO")
```

#### age

Predictive? Maybe

* 177 (```r round(177/891*100,2)```%) rows have null `age` value, so will be hard to use without imputing data somehow
```{r}
summary(combined[1:891, "age"])
```


Perhaps some trend in Male 1st class
Otherwise, only really showing that children had better survival rates.
```{r echo=FALSE, warning=FALSE, fig.height=7}
# bin age by 10
combined$age.bin <- cut(ifelse(is.na(combined$age),105, combined$age), c(0,10,20,30,40,50,60,80,120), labels = c(0,10,20,30,40,50,60,"na"))

age.bin.summary <- combined[1:891,] %>% 
  group_by(age.bin, sex, pclass, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

b1 <- ggplot(age.bin.summary, aes(x= age.bin, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~sex+pclass, ncol=3)

b2 <- ggplot(age.bin.summary, aes(x= age.bin, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~sex+pclass, ncol=3)

cowplot::plot_grid(b1,b2, ncol=1, labels = "AUTO")
```


#### name --> title

Predictive? **Yes**

##### Name Patterns
*Mr.*: `<lname>, <title>. <fname>`

*Mrs.*: `<lname>, <title>. <husband fname> <husband mname> (<fname> <mname>)`

*Ms.*: `<lname>, <title>. <fname>`


Extract last names and titles from `name` and add to combined data set

```{r echo=FALSE} 

## returns a list of names, where each name is separated into a vector with the part before and after the comma
name.splits <- str_split(combined[,"name"],', ')
#str_split(combined[1:5,"name"],', ')[[2]][2]

## pull first part of each name before comma (last name)
last.names <- sapply(name.splits, '[', 1)
combined$last.name <- last.names

## pull 2nd part of each name after the comma and before space (title)
name.splits <- str_split(sapply(name.splits,"[", 2), " ")
titles <- sapply(name.splits,"[",1)
first.names <- sapply(name.splits,"[",2)
combined$title <- titles
combined$first.name <- first.names

unique(combined$title)

```

Clean up titles and group them together
```{r echo=FALSE}
titles[titles %in% c("Jonkheer.","Don.")] <- "Sir."
titles[titles %in% c("Lady.","Dona.","the")] <- "Lady."
titles[titles %in% c("Col.","Capt.","Major.")] <- "Officer."
titles[titles %in% c("Mme.")] <- "Mrs."
titles[titles %in% c("Mlle.","Ms.")] <- "Miss."

combined$title <- as.factor(titles)

```


Summarize them:

```{r echo=FALSE}
title.summary <- combined[1:891,] %>% 
  group_by(title, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

c1 <- ggplot(title.summary, aes(x= title, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  theme(legend.position="bottom") +
  coord_flip()


c2 <- ggplot(title.summary, aes(x= title, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  theme(legend.position="bottom") +
  coord_flip()

cowplot::plot_grid(c1,c2, labels = "AUTO", ncol=2)
```



#### sibsp

Predictive? **Yes**


```{r}
summary(combined$sibsp)
```

```{r echo=FALSE}
sibsp.summary <- combined[1:891,] %>% 
  group_by(sibsp, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

d1 <- ggplot(sibsp.summary, aes(x= sibsp, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

d2 <- ggplot(sibsp.summary, aes(x= sibsp, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

cowplot::plot_grid(d1,d2, ncol=1, labels = "AUTO")
```


#### parch

Predictive? **maybe**


```{r}
summary(combined$parch)
```

```{r echo=FALSE}
parch.summary <- combined[1:891,] %>% 
  group_by(parch, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

d1 <- ggplot(parch.summary, aes(x= parch, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

d2 <- ggplot(parch.summary, aes(x= parch, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

cowplot::plot_grid(d1,d2, ncol=1, labels = "AUTO")

```

Is having children impactful to survival?  less is better
```{r echo=FALSE, results=FALSE, fig.height=12}
parch.summary <- combined[1:891,] %>% 
  group_by(parch, title, pclass, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

d1 <- ggplot(parch.summary, aes(x= parch, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~title+pclass,ncol=3)

d2 <- ggplot(parch.summary, aes(x= parch, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~title+pclass,ncol=3)

cowplot::plot_grid(d1,d2, ncol=1, labels = "AUTO")
```

#### sibsp + parch --> family.size

Predictive? **Maybe**

```{r echo = FALSE}
combined$family.size <- combined$sibsp + combined$parch
family.size.summary <- combined[1:891,] %>% 
  group_by(family.size, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

d1 <- ggplot(family.size.summary, aes(x= family.size, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

d2 <- ggplot(family.size.summary, aes(x= family.size, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7)

cowplot::plot_grid(d1,d2, ncol=1, labels = "AUTO")
```

Potential `survival` vs. `family.size` trends:

* Mr's 1st class
* Master 3rd class
* Miss / Mrses 3rd class

```{r echo=FALSE, fig.height=10}
family.size.summary <- combined[1:891,] %>% 
  group_by(family.size, title, pclass, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

d1 <- ggplot(family.size.summary, aes(x= family.size, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~title+pclass,ncol = 3)

d2 <- ggplot(family.size.summary, aes(x= family.size, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~title+pclass,ncol = 3)

cowplot::plot_grid(d1,d2, ncol=1, labels = "AUTO")
```



#### fare
Predictive? **Maybe** for Mr's in 1st class.

```{r}
summary(combined$fare)
```

* Fare looks to be a sum of the fare paid for a **ticket**.
* Looks like there are instances where a ticket is shared by multiple passengers.  in these cases, the fare is the same across these passengers.
* This case is a wealthy family (mother and son) traveling with two non-family members (servants?).  Mother and son share 3 rooms together.


```{r}
combined[which(combined$ticket == "PC 17755"),c("passengerid", "age", "name", "fare", "ticket","cabin","family.size")]
```

* There are also some data suggesting that getting mroe rooms could be associated with higher fare


For a first stab, let's try normalizing for number of passengers by averaging the fare by number of people sharing that ticket.

```{r echo=FALSE}
ticket.party.size <- rep(0, nrow(combined))
avg.fare <- rep(0.0, nrow(combined))
tickets <- unique(combined$ticket)

## for each ticket
for (i in 1:length(tickets)) {
  current.ticket <- tickets[i]
  ## get indexes associated with ticket
  party.indexes <- which(combined$ticket == current.ticket)
  ## calculate average fare per passenger for this ticket
  avg.current.fare <- combined[party.indexes[1], "fare"] / length(party.indexes)
  
  ## set avg fare and ticket party size for those people in that ticket party.
  for (j in 1:length(party.indexes)) {
    ticket.party.size[party.indexes[j]] <- length(party.indexes)
    avg.fare[party.indexes[j]] <- avg.current.fare
  }
}

combined$ticket.party.size <- ticket.party.size
combined$avg.fare <- avg.fare

```

we have 1 n/a for avg. fare, so will want to impute value in order to use in model.
```{r echo = FALSE}
summary(combined$ticket.party.size)
summary(combined$avg.fare)

## impute value for 1 missing avg fare from 370 similar passengers
combined[which(is.na(combined$avg.fare)),]
combined[which(combined$passengerid == "1044"),"avg.fare"] <- mean(combined[which(combined$sex == "male" 
               & combined$pclass == 3
               & combined$family.size == 0
               & combined$title == "Mr."
               & is.na(combined$avg.fare) == FALSE
               ), "avg.fare"])

```

Graph relationship between survival and avg fare, by class and title.

* relationship between avg fare and survival isn't clear.
* family.size definitely seems to be an indicator for survival within pclass = 3
```{r echo=FALSE}
## graph relationship between survival and avg fare, by class and title
ggplot(combined[1:891,], aes(x = avg.fare, y = family.size, color = survived)) + 
  geom_point() +
  facet_wrap(~title+pclass, ncol = 3)
```

#### cabin
Predictive?  **Not greatly so.**  Lots of missing values.  Most of the predictive power comes the trend that a passenger having any cabin data reported increases their chance of survival.

Lots of empty string values `""`: ```r length(which(combined$cabin==""))``` out of 1309 -> ```r round(length(which(combined$cabin==""))/length(combined$cabin)*100,0)```%

Look at first letter only.

Appears like first class has the most reported cabin data.  Yet not much of a trend within class. Having any cabin data reported might be correlated to having better survival rate within 1st/2nd class.
```{r echo=FALSE}
combined$cabin.first.letter <- as.factor(ifelse(substring(combined$cabin,1,1)=="","U",substring(combined$cabin,1,1)))

cabin.first.letter.summary <- combined[1:891,] %>% 
  group_by(cabin.first.letter, pclass, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

a1 <- ggplot(cabin.first.letter.summary, aes(x= cabin.first.letter, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~pclass, ncol=3)

a2 <- ggplot(cabin.first.letter.summary, aes(x= cabin.first.letter, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~pclass, ncol=3)

cowplot::plot_grid(a1,a2, ncol=1, labels = "AUTO")

```

Look at people with multiple cabins: 

**Training**: ```r length(train[grep(" ",train$cabin),"cabin"])``` of ```r length(which(train$cabin!=""))``` => ```r round(length(train[grep(" ",train$cabin),"cabin"])/length(which(train$cabin!=""))*100, 0)``` % of reported cabins in training dataset, or ```r round(length(train[grep(" ",train$cabin),"cabin"])/length(train$cabin)*100, 0)``` % of total training dataset

**Combined**: ```r length(combined[grep(" ",combined$cabin),"cabin"])``` of ```r length(which(combined$cabin!=""))``` => ```r round(length(combined[grep(" ",combined$cabin),"cabin"])/length(which(combined$cabin!=""))*100, 0)```% of reported cabins in combined data set, or ```r round(length(combined[grep(" ",combined$cabin),"cabin"])/length(combined$cabin)*100, 0)``` % of total combined dataset

Create a feature: 

* U = unreported cabin
* S = single cabin
* M = multiple cabin

Looks like there could be a difference between having any reported cabin data vs. none in 1st class.  Let's just aggregate M and S together

```{r echo=FALSE, fig.height=7}
combined$cabin.agg <- as.factor(ifelse(combined$cabin==""
                             , "U"
                             ,ifelse(str_detect(combined$cabin, " ")
                                     ,"M"
                                     ,"S")))


cabin.agg.summary <- combined[1:891,] %>% 
  group_by(cabin.agg, pclass, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

a1 <- ggplot(cabin.agg.summary, aes(x= cabin.agg, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~pclass, ncol=3)

a2 <- ggplot(cabin.agg.summary, aes(x= cabin.agg, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~pclass, ncol=3)

cowplot::plot_grid(a1,a2, ncol=1, labels = "AUTO")

## aggregate M and U together
combined$cabin.agg <- as.factor(ifelse(combined$cabin.agg=="M","S", combined$cabin.agg))
```

#### embarked

Predictive? **No**, controlling for pclass, the survival rates look similar from each embarked location

```{r}
embarked.summary <- combined[1:891,] %>% 
  group_by(embarked, pclass, survived) %>% 
  summarize(count=n()) %>% 
  mutate(pct = count/sum(count))

b1 <- ggplot(embarked.summary, aes(x= embarked, y = pct, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~pclass)

b2 <- ggplot(embarked.summary, aes(x= embarked, y = count, fill = survived)) +
  geom_bar(stat="identity", width = 0.7) +
  facet_wrap(~pclass)

cowplot::plot_grid(b1,b2, ncol=1, labels = "AUTO")
```

#### Summary of relevant features

**Predictive:**

* sex : women > men
* pclass : 1 > 2 > 3
* title : combination of above, plus splitting out male children

**Maybe Predictive**

* family.size : having larger families could hurt survival in 3rd class
* cabin.agg : having any cabin data could help survival
* avg fare: having lower avg fare could help in male 1st class

**Not Predictive**

* embarked
* age: children do have better survival rates, otherwise a wash. could try to separate young misses vs. older misses better -- this might matter for 2nd class (not so much for 1st / 3rd)


## (2) Exploratory modeling

### Load Tools:
```{r echo = FALSE}
library(randomForest)
# install.packages("rpart")
# install.packages("rpart.plot")
library(rpart)
# library(rpart.plot)
# had to run `brew install libomp` initially in terminal to get caret installation to work on my mac os
# install.packages("caret"), dependencies = TRUE)
# install.packages("doSNOW", dependencies = TRUE)
library(caret)
library(doSNOW)


##
rf.label <- as.factor(train$survived)
```

### Build and Compare Training Models

#### Model 1: Random Forest - sex, pclass
26.15% OOB error rate

```{r echo = FALSE}
## Subset features from training dataset
rf.train.1 <- combined[1:891, c("pclass","sex")]
set.seed(1234) ## allows for reproduceability across trials

## train model
rf.1 <- randomForest(x = rf.train.1
                     , y = rf.label
                     , importance = TRUE ## track relative importance of features
                     , ntree = 1000 ## default is 500 trees, ok
                     )
## view confusion matrix
rf.1

```

#### Model 2: Random Forest - title, pclass
20.76% OOB error rate

```{r echo = FALSE}

## Subset features from training dataset
rf.train.2 <- combined[1:891, c("title","pclass")]
set.seed(1234) ## allows for reproduceability across trials

## train model
rf.2 <- randomForest(x = rf.train.2
                     , y = rf.label
                     , importance = TRUE ## track relative importance of features
                     , ntree = 1000 ## default is 500 trees, ok
                     )
## view confusion matrix
rf.2

```

#### Model 3: Random Forest - title, pclass,sex
19.98% OOB error rate, adding sex seems to greatly improve ability to predict survival

```{r echo = FALSE}

## Subset features from training dataset
rf.train.3 <- combined[1:891, c("title","pclass","sex")]
set.seed(1234) ## allows for reproduceability across trials

## train model
rf.3 <- randomForest(x = rf.train.3
                     , y = rf.label
                     , importance = TRUE ## track relative importance of features
                     , ntree = 1000 ## default is 500 trees, ok
                     )
## view confusion matrix
rf.3

```

#### Model 4: Random Forest - title, pclass,sex, family.size
16.84% OOB error rate

```{r echo = FALSE}

## Subset features from training dataset
rf.train.4 <- combined[1:891, c("title","pclass","sex","family.size")]
set.seed(1234) ## allows for reproduceability across trials

## train model
rf.4 <- randomForest(x = rf.train.4
                     , y = rf.label
                     , importance = TRUE ## track relative importance of features
                     , ntree = 1000 ## default is 500 trees, ok
                     )
## view confusion matrix
rf.4

```

#### Model 5: Random Forest - title, pclass,sex, family.size, cabin.agg
16.95% OOB error rate

```{r echo = FALSE}

## Subset features from training dataset
rf.train.5 <- combined[1:891, c("title","pclass","sex","family.size","cabin.agg")]
set.seed(1234) ## allows for reproduceability across trials

## train model
rf.5 <- randomForest(x = rf.train.5
                     , y = rf.label
                     , importance = TRUE ## track relative importance of features
                     , ntree = 1000 ## default is 500 trees, ok
                     )
## view confusion matrix
rf.5

```

#### Model 6: Random Forest - title, pclass,sex, family.size, avg.fare
16.61% OOB error rate

```{r echo = FALSE}

## Subset features from training dataset
rf.train.6 <- combined[1:891, c("title","pclass","sex","family.size","avg.fare")]
set.seed(1234) ## allows for reproduceability across trials

## train model
rf.6 <- randomForest(x = rf.train.6
                     , y = rf.label
                     , importance = TRUE ## track relative importance of features
                     , ntree = 1000 ## default is 500 trees, ok
                     )
## view confusion matrix
rf.6

```


#### Model 6: Random Forest - title, pclass,sex, family.size, avg.fare, after relabeling for female Dr. => Mrs.
16.61% OOB error rate

```{r echo = FALSE}

combined[which(combined$title %in% c("Dr.")),]
combined[combined$passengerid=="797","title"] <- "Mrs."

## Subset features from training dataset
rf.train.6 <- combined[1:891, c("title","pclass","sex","family.size","avg.fare")]
set.seed(1234) ## allows for reproduceability across trials

## train model
rf.6 <- randomForest(x = rf.train.6
                     , y = rf.label
                     , importance = TRUE ## track relative importance of features
                     , ntree = 1000 ## default is 500 trees, ok
                     )
## view confusion matrix
rf.6

# plot feature importance
# varImpPlot(rf.6)

```
```{r echo=FALSE}
#try identifying misses alone
combined$miss.alone <- ifelse(combined$sex=="female"
               & combined$title == "Miss."
               & combined$family.size == 0,TRUE,FALSE)

#try identifying mrses alone
combined$mrs.alone <- ifelse(combined$sex=="female"
               & combined$title == "Mrs."
               & combined$family.size == 0,TRUE,FALSE)
```



### Run Cross Validation

Using Repeated K-Fold Cross Validation

* with 3 folds
* and 10 iterations

And using random partitioning decision trees, so we can understand feature importance more easily.

#### Set up wrapper functions for running CV using Rpart and randomForest
```{r echo=FALSE}
## recursive partitioning (rpart) & regression trees wrapper function for running cross validation
## using N cores
## given features, labels, seed, and CV Control object.
rpart.cv <- function(seed, training, labels, ctrl) {
  #Start cluster
  cl <- makeCluster(6, type = "SOCK")
  registerDoSNOW(cl)
  
  set.seed(seed)
  # Leverage formula interface for training
  # this runs cross validation
  rpart.cv <- train(x = training, y = labels, method = "rpart", tuneLength = 30, 
                    trControl = ctrl)
  
  #Shutdown cluster
  stopCluster(cl)
  
  return (rpart.cv)
}

## randomForest wrapper function for running cross validation
## using N cores
## given features, labels, seed, and CV Control object.
rforest.cv <- function(seed, training, labels, ctrl) {
  #Start cluster
  cl <- makeCluster(6, type = "SOCK")
  registerDoSNOW(cl)
  
  set.seed(seed)
  # Leverage formula interface for training
  # this runs cross validation
  rForest.cv <- train(x = training, y = labels, method = "rf", tuneLength = 30, , ntree = 1000,
                    trControl = ctrl)
  
  #Shutdown cluster
  stopCluster(cl)
  
  return (rForest.cv)
}

## try k-fold cross validation with 3 folds (67% of data used to train)
## without knowingn anything about data, 10folds is good to start
## but also, usually mimicking proportions of actual training and test data sets works well.
set.seed(54321)

# returns indices of rf.label to train model
# 3 folds, run 10 times
# folds split training data into 3rds such that each row from training set is used once per iteration
# by averaging error over these folds / iterations, we get a better sense of the model's prediction power on generalized data. still could be inaccurate if training data is biased.
cv.3.folds <- createMultiFolds(rf.label, k = 3, times = 10)

## set up caret's trainControl object
## 3 folds, run 10 times
## pass in the 
ctrl.3 <- trainControl(method = "repeatedcv", number = 3, repeats = 10
                       , index = cv.3.folds)

```

#### Model 5: Rpart - title, pclass,sex, family.size 0.8282 Accuracy with rpart, 0.8236 Accuracy with rforest 1000 trees
```{r}
# Grab features
features <- c("title","pclass","sex","family.size")
rpart.train.1 <- combined[1:891, features]

# Run rpart CV and check out results
rpart.1.cv.1 <- rpart.cv(94622, rpart.train.1, rf.label, ctrl.3)
rpart.1.cv.1

# Plot
# prp(rpart.1.cv.1$finalModel, type = 0, extra = 1, under = TRUE)


# Run rforest CV and check out results
rForest.1.cv.1 <- rforest.cv(94622, rpart.train.1, rf.label, ctrl.3)
rForest.1.cv.1


```

#### Model 6: Rpart - title, pclass,sex, family.size, avg.fare, 0.8327 Accuracy using rpart, 0.8259 Accuracy using randomForest with 1000 trees
```{r}
# Grab features
features <- c("title","pclass","sex","family.size","avg.fare")
rpart.train.1 <- combined[1:891, features]

# Run rpart CV and check out results
rpart.1.cv.1 <- rpart.cv(94622, rpart.train.1, rf.label, ctrl.3)
rpart.1.cv.1

# Plot
# prp(rpart.1.cv.1$finalModel, type = 0, extra = 1, under = TRUE)

# Run rforest CV and check out results
rForest.1.cv.1 <- rforest.cv(94622, rpart.train.1, rf.label, ctrl.3)
rForest.1.cv.1


```


### Best model based on CV is RPart using title, pclass,sex, family.size, avg.fare, 0.8327 Accuracy

Make Predictions
```{r}

## best model
rpart.6 <- rpart(data = combined[1:891,]
                 , survived ~ title + pclass + sex + family.size + avg.fare)

features <- c("title","pclass","sex","family.size","avg.fare")


# predict on training set
predictions <- predict(rpart.6, newdata = combined[1:891, features],type = "vector")

predictions <- predictions-1
predictions <- data.frame(
  predicted = predictions
  , PassengerId = combined$passengerid[1:891]
  , Survived = combined$survived[1:891]
  )


## accuracy on training set = 0.84736
nrow(predictions[which(predictions$predicted == predictions$Survived),]) / nrow(predictions)

# predict on test set
rpart.test.6 <- combined[892:nrow(combined), features]
predictions <- predict(rpart.6, newdata = rpart.test.6,type = "vector")

predictions <- predictions-1
predictions <- data.frame(PassengerId = combined$passengerid[892:1309],Survived = predictions)


# write to csv for submission
write.csv(predictions
          , file="predictions.csv"
          , row.names = FALSE)

```


### Other Analysis 

#### Look at (male) titles that are predicted 100% not survived
```{r echo = FALSE}

# look at key populations that are incorrectly predicted
# and potential features that could aid in predicting survival
# combined[which(!(combined$title %in% c("Dr.","Mr.","Officer.","Reverend.","Sir."))
#                & combined$pclass == 3
#                & combined$family.size < 4),]
# 
# combined[which(combined$title %in% c("Dr.","Mr.","Officer.","Reverend.","Sir."))
#                ,]


## look at passengers ordered by ticket
# combined.sortbyticket <- combined %>%
  # arrange(pclass, ticket)

# View(combined.sortbyticket)
```



#### Determine if Mrses are onboard without husband and if that matters
```{r}

# # match mrses to their husbands
# sub("Mrs\\..*\\(","", combined$name)
# # install.packages("gsubfn")
# library(gsubfn)
# 
# combined$husband.name <- gsub(" \\(", "", gsub("Mrs. ", "", strapplyc(combined$name, "Mrs\\..*\\(", simplify = TRUE)))
# combined$husband.name
# combined$first.name
# 
# name.splits <- str_split(combined[,"husband.name"],' ')
# name.splits <- str_split(sapply(name.splits,"[", 1), " ")
# combined$husband.first.name <- name.splits
# combined$husband.first.name2 <- ifelse(combined$title == "Mrs.", combined$first.name, NA)
# 
# combined$husband.first_name2 <- combined[which(str_detect(combined$husband.first.name2,"\\(")),"husband.first.name2"] <- NA
# 
# husband.count <- rep(0, nrow(combined))
# husband.names <- unique(combined$husband.first.name2)
# unique.tickets <- unique(combined$ticket)
# 
# unique.tickets
# 
# ## Identify if Mrs. passengers had husband onboard based on name matches
# for (i in 1:length(unique.tickets)) {
#   current.ticket <- unique.tickets[i]
#   ## get Mrs.'s husband.fname
#   husband.fname <- combined[which(combined$ticket == current.ticket & combined$title == "Mrs."),"husband.first.name2"]
#   ## get indices of matching husbands
#   husband.matches <- which(combined$ticket == current.ticket & combined$title %in% c("Mr.","Officer.","Sir.","Dr.","Rev.") & combined$first.name == husband.fname)
#   ## calculate average fare per passenger for this ticket
#   husband.count[which(combined$ticket == current.ticket & combined$title == "Mrs.")] <- length(husband.matches)
# }
# 
# combined$husband.onboard <- ifelse(husband.count>0, TRUE, FALSE)
# 
# husband.onboard.summary <- combined[1:891,] %>% 
#   group_by(husband.onboard, pclass, survived) %>% 
#   filter(title=="Mrs.") %>%
#   summarize(count=n()) %>% 
#   mutate(pct = count/sum(count))
# 
# d1 <- ggplot(husband.onboard.summary, aes(x= husband.onboard, y = pct, fill = survived)) +
#   geom_bar(stat="identity", width = 0.7) + facet_wrap(~pclass) + ggtitle("pclass")
# 
# d2 <- ggplot(husband.onboard.summary, aes(x= husband.onboard, y = count, fill = survived)) +
#   geom_bar(stat="identity", width = 0.7) + facet_wrap(~pclass) + ggtitle("pclass")
# 
# cowplot::plot_grid(d1,d2, ncol=1, labels = "AUTO")
# 
# ?ggplot


```

